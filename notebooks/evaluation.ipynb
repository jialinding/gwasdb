{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we will evaluate the relations extracted in all the other notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import cPickle\n",
    "import numpy as np\n",
    "\n",
    "# import snorkel and gwasdb\n",
    "sys.path.append('../snorkel')\n",
    "sys.path.append('../src')\n",
    "sys.path.append('../src/crawler')\n",
    "\n",
    "# set up paths\n",
    "abstract_dir = '../data/db/papers'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load documents ids from paper/phenotype relation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "589 paper ids loaded, e.g.:\n",
      "['25086665', '23349640', '20436471', '24714607', '22174851']\n"
     ]
    }
   ],
   "source": [
    "pmids = list()\n",
    "with open('results/nb-output/phenotypes.extracted.tsv') as f:\n",
    "    for line in f:\n",
    "        pmid, _ = line.strip().split('\\t')\n",
    "        pmids.append(pmid)\n",
    "        \n",
    "print len(pmids), 'paper ids loaded, e.g.:'\n",
    "print pmids[:5]                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading results from other notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to collect the relations that have been extracted by the previous modules. \n",
    "\n",
    "The paths below point to pre-computed results; you will need to modify these paths to run them on your own input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Phenotype/rsid relations from tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2130 loaded, e.g.:\n",
      "[(('21738491', 1, 3, 2), ('rs12143842', 'QT')), (('20585627', 2, 8, 1), ('rs12931267', 'Red hair')), (('17903306', 4, 31, 1), ('rs2195926', 'SDNN')), (('17903301', 2, 9, 1), ('rs10514431', 'left ventricular diastolic dimension')), (('24376456', 3, 36, 2), ('rs2410182', 'Coronary heart disease'))]\n"
     ]
    }
   ],
   "source": [
    "phen_table_associations = dict()\n",
    "with open('results/nb-output/phen-rsid.table.rel.all.tsv') as f:\n",
    "    for line in f:\n",
    "        fields = line.strip().split('\\t')\n",
    "        pmid, rsid, phen, pval, _, table_id, row_id, col_id = fields\n",
    "        pval, table_id, row_id, col_id = float(pval), int(table_id), int(row_id), int(col_id)\n",
    "        # note that we assume that an rsid at a givel location will correspond to 1 phenotype\n",
    "        phen_table_associations[pmid, table_id, row_id, col_id] = (rsid, phen)\n",
    "        \n",
    "print len(phen_table_associations), 'loaded, e.g.:'\n",
    "print phen_table_associations.items()[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### PMID/Phenotype relations extracted from titles/abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "589 phenotypes loaded, e.g.:\n",
      "[('23738518', 'Reading|Language'), ('22044751', 'Chronic Kidney Disease'), ('21298047', 'European-Origin|Substance Dependence'), ('23104006', 'Endometriosis'), ('20072603', 'Osteoporosis')]\n"
     ]
    }
   ],
   "source": [
    "phen_text_associations = dict()\n",
    "with open('results/nb-output/phenotypes.extracted.tsv') as f:\n",
    "    for line in f:\n",
    "        pmid, phen = line.strip().split('\\t')\n",
    "        phen_text_associations[pmid] = phen\n",
    "        \n",
    "print len(phen_text_associations), 'phenotypes loaded, e.g.:'\n",
    "print phen_text_associations.items()[:5]                           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RSID/Pvalue relations extracted from tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10062 relations loaded, e.g.:\n",
      "[(('22504420', 0, 33, 0, 'rs4790881'), set([0.0, 0.0006, 2e-06])), (('22396660', 1, 6, 1, 'rs11746443'), set([0.98])), (('24094242', 1, 19, 0, 'rs7267979'), set([0.0])), (('17903302', 1, 21, 2, 'rs1408263'), set([2.4e-05])), (('17903294', 2, 20, 1, 'rs727979'), set([2.6e-05, 7e-06]))]\n"
     ]
    }
   ],
   "source": [
    "pval_table_associations = dict()\n",
    "with open('results/nb-output/pval-rsid.raw.cols.filtered.tsv') as f:\n",
    "    for line in f:\n",
    "        pmid, rsid, table_id, row_id, col_id, pval = line.strip().split('\\t')\n",
    "        pval, table_id, row_id, col_id = float(pval), int(table_id), int(row_id), int(col_id)\n",
    "        \n",
    "        key = pmid, table_id, row_id, col_id, rsid\n",
    "        if key not in pval_table_associations: pval_table_associations[key] = set()\n",
    "        pval_table_associations[key].add(pval)\n",
    "\n",
    "print len(pval_table_associations), 'relations loaded, e.g.:'\n",
    "print pval_table_associations.items()[:5]      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Table annotations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "671 suspcious table ids loaded, e.g.:\n",
      "[('21273288', 1), ('19343178', 1), ('23028341', 2), ('23844046', 3), ('24143190', 1)]\n"
     ]
    }
   ],
   "source": [
    "non_gwas_tables = set()\n",
    "with open('results/nb-output/table-annotations.tsv') as f:\n",
    "    for line in f:\n",
    "        pmid, table_id, pval_found, lod_found = line.strip().split('\\t')\n",
    "        if int(pval_found) or int(lod_found):\n",
    "            non_gwas_tables.add((pmid, int(table_id)))\n",
    "                                  \n",
    "print len(non_gwas_tables), 'suspcious table ids loaded, e.g.:'\n",
    "print list(non_gwas_tables)[:5]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Singleton RSids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12309 loaded, e.g.:\n",
      "[(('23128233', 0, 17, 2), 'rs9264942'), (('25129146', 0, 8, 0), 'rs1642764'), (('23754948', 1, 6, 0), 'rs10478424'), (('17903301', 2, 9, 1), 'rs10514431'), (('17903307', 1, 66, 1), 'rs1393593')]\n"
     ]
    }
   ],
   "source": [
    "singleton_associations = dict()\n",
    "with open('results/nb-output/rsids.singletons.all.tsv') as f:\n",
    "    for line in f:\n",
    "        pmid, table_id, row_id, col_id, rsid = line.strip().split()\n",
    "        table_id, row_id, col_id = int(table_id), int(row_id), int(col_id)\n",
    "        singleton_associations[pmid, table_id, row_id, col_id] = rsid\n",
    "\n",
    "print len(singleton_associations), 'loaded, e.g.:'\n",
    "print singleton_associations.items()[:5]\n",
    "\n",
    "n_singletons_by_table = dict()\n",
    "for (pmid, table_id, row_id, col_id), rsid in singleton_associations.items():\n",
    "    key = pmid, table_id\n",
    "    if key not in n_singletons_by_table: n_singletons_by_table[key] = 0\n",
    "    n_singletons_by_table[key] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct a list valid relations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we combine all of the above relations into a single set of associations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7362 associations, e.g.:\n",
      "[('21738491', 'rs12143842', (1, 3, 2), ('Sudden Cardiac Death', 'QT')), ('20585627', 'rs12931267', (2, 8, 1), ('Common Traits', 'Red hair')), ('17903295', 'rs2543600', (3, 14, 2), ('Age-Related Phenotypes|Longevity', 'Age at death')), ('20838585', 'rs726914', (0, 16, 3), ('Cardiovascular Disease', 'systolic BP')), ('20526338', 'rs4311994', (1, 13, 0), ('Platelet Aggregation', 'Epi 2 u M'))]\n",
      "There were 469 singletons\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean(phen):\n",
    "    phen = re.sub('[)():.]+', '', phen)\n",
    "    phen = re.sub('^or ', '', phen)\n",
    "    phen = phen.strip()\n",
    "    return phen\n",
    "\n",
    "associations = []\n",
    "\n",
    "tables_found = {(pmid, table_id) for pmid, table_id, _, _, _ in pval_table_associations} # with pvalues\n",
    "tables_found.update(non_gwas_tables)\n",
    "\n",
    "# record table associations wth pval < 1e-5 or no pval reported\n",
    "chosen_rsids = set()\n",
    "for (pmid, table_id, row_id, col_id), (rsid, loc_phen) in phen_table_associations.items():\n",
    "    pvals = pval_table_associations.get((pmid, table_id, row_id, col_id, rsid), [])\n",
    "    glob_phen = clean(phen_text_associations[pmid])\n",
    "    if (pvals and min(pvals) < 1e-5) or (not pvals and (pmid, table_id) not in tables_found):\n",
    "        associations.append((pmid, rsid, (table_id, row_id, col_id), (glob_phen, loc_phen)))\n",
    "        chosen_rsids.add((pmid, table_id, row_id, col_id, rsid))\n",
    "\n",
    "\n",
    "# record associations with no local phenotype\n",
    "for (pmid, table_id, row_id, col_id, rsid), pvals in pval_table_associations.items():\n",
    "    # skip low-pvalue snps and snps that we already added\n",
    "    if pvals and min(pvals) > 1e-5: continue\n",
    "    if (pmid, table_id, row_id, col_id, rsid) in chosen_rsids: continue\n",
    "    \n",
    "    # append with global phenotype\n",
    "    phen = clean(phen_text_associations[pmid])\n",
    "    associations.append((pmid, rsid, (table_id, row_id, col_id), (phen, '')))    \n",
    "    chosen_rsids.add((pmid, table_id, row_id, col_id, rsid))\n",
    "\n",
    "# record singletons\n",
    "n_singletons_added = 0\n",
    "for (pmid, table_id, row_id, col_id), rsid in singleton_associations.items():\n",
    "    if (pmid, table_id, row_id, col_id, rsid) in chosen_rsids: continue\n",
    "    if (pmid, table_id) in tables_found: continue\n",
    "    if n_singletons_by_table[(pmid, table_id)] < 30: continue\n",
    "    phen = clean(phen_text_associations[pmid])\n",
    "    associations.append((pmid, rsid, (table_id, row_id, col_id), (phen, ''))) \n",
    "    n_singletons_added += 1\n",
    "\n",
    "print len(associations), 'associations, e.g.:'\n",
    "print associations[:5]    \n",
    "print 'There were %d singletons' % n_singletons_added"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the associations extracted by our system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with open('associations.tsv', 'w') as f:\n",
    "    for (pmid, rsid, (table_id, row_id, col_id), (glob_phen, loc_phen)) in associations:\n",
    "        pvals = pval_table_associations.get((pmid, table_id, row_id, col_id, rsid), [])\n",
    "        pval = min(pvals) if pvals else -1\n",
    "        loc_phen = '-' if not loc_phen else loc_phen\n",
    "\n",
    "        f.write('%s\\t%s\\t%s\\t%s\\t%f\\n' % (pmid, rsid, glob_phen, loc_phen, pval))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now proceed to evaluate these relations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparing to GWAS Central"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we want to evalaute the recall relative to existing databases.\n",
    "\n",
    "We start with GWAS Central, which is more extensive than GWAS Catalog (for papers up to ~2013), and which contains very precise phenotype labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "589 documents, 6760 associations\n"
     ]
    }
   ],
   "source": [
    "from db.kb import KnowledgeBase\n",
    "\n",
    "kb = KnowledgeBase()\n",
    "assocs = [assoc for pmid in pmids for assoc in kb.assoc_by_pmid(pmid) if assoc.source == 'gwas_central' and assoc.pvalue < 1e-5]\n",
    "# assocs = [assoc for pmid in pmids for assoc in kb.assoc_by_pmid(pmid) if assoc.source == 'gwas_central']\n",
    "\n",
    "print '%d documents, %d associations' % (len(pmids), len(assocs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up map of GWC to GWASDB phenotypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because each database uses different words to describe phenotypes (words chosen by the human curators), we need a mapping between equivalent phenotype names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This cell records phenotypes associated with each (pmid, rsid) pair\n",
    "# in both our relations and ones in GWC.\n",
    "\n",
    "rel_dict = { (pmid, rsid) : set() for (pmid, rsid, _, _) in associations }\n",
    "for (pmid, rsid, loc, phen) in associations:\n",
    "    rel_dict[(pmid, rsid)].add(phen)\n",
    "\n",
    "gold_rel_dict = { (a.paper.pubmed_id, a.snp.rs_id) : set() for a in assocs }\n",
    "for a in assocs:\n",
    "    gold_rel_dict[(a.paper.pubmed_id, a.snp.rs_id)].add(a.phenotype.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We generate a map of all potential matches. \n",
    "\n",
    "Phenotypes `p1`, `p2` could match if we find `(pmid, rsid, p1)` in GWC and\n",
    "`(pmid, rsid, p2)` in our relations.\n",
    "\n",
    "We save this to a file and manually specify if each `(p1, p2)` are \n",
    "equivalent. We can also load existing mappings via the `phen_scores` dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_set = set()\n",
    "for a in assocs:\n",
    "    s1 = gold_rel_dict[(a.paper.pubmed_id, a.snp.rs_id)]\n",
    "    s2 = rel_dict.get((str(a.paper.pubmed_id), a.snp.rs_id), None)\n",
    "    if s1 and s2:\n",
    "        for name1 in s1:\n",
    "            for name2a, name2b in s2:\n",
    "                name1 = str(name1)\n",
    "                try:\n",
    "                    score = phen_scores.get((name1.lower(), name2a.lower(), name2b.lower()), '')\n",
    "                except:\n",
    "                    score = ''\n",
    "                out_set.add('%s\\t%s\\t%s\\t%s\\n' % (name1, name2a, name2b, score))\n",
    "\n",
    "with open('phenotype.mapping.tsv', 'w') as f:                    \n",
    "    for out_str in out_set:\n",
    "        f.write(out_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This loads our pre-annotated mapping of phenotypes.\n",
    "\n",
    "Each pair of phenotypes has a score: 0: incorrect, 1: incorrect because acronym could not be resolve, 2: generally correct, but imprecise, 3: fully correct (at least as precise as the human-created label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded mapping for 499 relations.\n"
     ]
    }
   ],
   "source": [
    "phen_map = dict()\n",
    "phen_scores = dict()\n",
    "with open('util/phenotype.mapping.annotated.tsv') as f:                    \n",
    "    for line in f:\n",
    "        fields = line.strip().split('\\t')\n",
    "        fields = [re.sub('\"', '', f) for f in fields]\n",
    "        orig_name, glob_name, loc_name, score = fields\n",
    "\n",
    "        phen_scores[(orig_name.lower(), glob_name.lower(), loc_name.lower())] = score\n",
    "        # change the tuple below to ('3',) in order to look at only maximally \n",
    "        # precise phenotypes\n",
    "        if score in ('2', '3',):\n",
    "            key = (glob_name, loc_name)\n",
    "            if key not in phen_map: phen_map[key] = set()\n",
    "            phen_map[key].add(orig_name) \n",
    "\n",
    "print 'Loaded mapping for %d relations.' % len(phen_map)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at recall relative to GWAS Central"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute recall over the subset of \"recoverable\" relations, which are ones that are found in the paper XML body. The following function determines if an RSID is present anywhere in the paper."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def paper_contains(pmid, quote):\n",
    "    with open('../data/db/papers/%d.xml' % pmid) as f:\n",
    "        txt = f.read()\n",
    "        return True if re.search(quote, txt) else False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now use our mapping to comapre against GWAS Central"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correctly identifed relations: 2486\n",
      "Incorrectly identifed b/c of wrong phenotype: 67\n",
      "Relations not found at all: 455\n",
      "Total relations in GWC: 3008\n",
      "Papers with most missed relations: [(19197348, 16), (18159244, 15), (23400010, 14), (21810271, 11), (24121790, 10), (24058526, 10), (22747683, 9), (22493691, 7), (22504420, 7), (21738487, 7)]\n"
     ]
    }
   ],
   "source": [
    "confirmed_assocs_gwcen = list()\n",
    "\n",
    "# display directly the results we found\n",
    "n_correct, n_imprecise, n_missing, n_wrong, n_total, n_new = 0, 0, 0, 0, 0, 0\n",
    "invalid_per_paper = { a.paper.pubmed_id : 0 for a in assocs }\n",
    "seen = set()\n",
    "for a in assocs:\n",
    "    if (a.paper.pubmed_id, a.snp.rs_id, a.phenotype.name) in seen: continue\n",
    "    seen.add((a.paper.pubmed_id, a.snp.rs_id, a.phenotype.name))\n",
    "    \n",
    "    gold_phen_set = {a.phenotype.name} # gwc phenotype string\n",
    "    # load the set of gwasdb phenotypes to which the snp was mapped in this paper\n",
    "    pred_phen_set = rel_dict.get((str(a.paper.pubmed_id), a.snp.rs_id), {}) \n",
    "    # translate these phenotypes into gwc phenotypes using our map\n",
    "    pred_phen_transl_set = {m for p in pred_phen_set for m in phen_map.get(p, {})}\n",
    "\n",
    "    if gold_phen_set & pred_phen_transl_set: \n",
    "        n_correct += 1\n",
    "        n_total += 1\n",
    "        # record the corresponding gwasdb associations as having been correctly recovered\n",
    "        correct_phenotypes = [p for p in pred_phen_set if phen_map.get(p, set()) & gold_phen_set]\n",
    "        for p in correct_phenotypes:\n",
    "            confirmed_assocs_gwcen.append( (str(a.paper.pubmed_id), a.snp.rs_id, p) )\n",
    "    else:\n",
    "        if paper_contains(a.paper.pubmed_id, a.snp.rs_id):\n",
    "            # this can be used to diagnose errors\n",
    "            if a.paper.pubmed_id == 888:\n",
    "                # print phenotypes\n",
    "                print a.snp.rs_id, gold_phen_set, pred_phen_set, pred_phen_transl_set\n",
    "            if pred_phen_set:\n",
    "                n_wrong += 1\n",
    "            else:\n",
    "                n_missing += 1\n",
    "            n_total += 1\n",
    "            invalid_per_paper[a.paper.pubmed_id] += 1\n",
    "\n",
    "print 'Correctly identifed relations:', n_correct\n",
    "print 'Incorrectly identifed b/c of wrong phenotype:', n_wrong\n",
    "print 'Relations not found at all:', n_missing\n",
    "print 'Total relations in GWC:', n_total\n",
    "\n",
    "print 'Papers with most missed relations:', sorted(invalid_per_paper.items(), key=lambda x: x[1], reverse=True)[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison to GWAS Catalog"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we repeat the same analysis with GWAS Catalog relations.\n",
    "\n",
    "GWAS Catalog uses less precise phenotypes, but contains many recent papers that are not in GWAS Central."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "589 documents, 9747 associations\n"
     ]
    }
   ],
   "source": [
    "from db.kb import KnowledgeBase\n",
    "\n",
    "kb = KnowledgeBase()\n",
    "assocs = [assoc for pmid in pmids for assoc in kb.assoc_by_pmid(pmid) if assoc.source == 'gwas_catalog' and assoc.pvalue < 1e-5]\n",
    "\n",
    "print '%d documents, %d associations' % (len(pmids), len(assocs))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up map of GWASdb to GWASCat phenotypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set up a phenotype map in the same way as above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rel_dict = { (pmid, rsid) : set() for (pmid, rsid, _, _) in associations }\n",
    "for (pmid, rsid, loc, phen) in associations:\n",
    "    rel_dict[(pmid, rsid)].add(phen)\n",
    "\n",
    "gold_rel_dict = { (a.paper.pubmed_id, a.snp.rs_id) : set() for a in assocs }\n",
    "for a in assocs:\n",
    "    gold_rel_dict[(a.paper.pubmed_id, a.snp.rs_id)].add(a.phenotype.name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "out_set = set()\n",
    "for a in assocs:\n",
    "    s1 = gold_rel_dict[(a.paper.pubmed_id, a.snp.rs_id)]\n",
    "    s2 = rel_dict.get((str(a.paper.pubmed_id), a.snp.rs_id), None)\n",
    "    if s1 and s2:\n",
    "        for name1 in s1:\n",
    "            for name2a, name2b in s2:\n",
    "                name1 = str(name1)\n",
    "                score = phen_scores.get((name1.lower(), name2a.lower(), name2b.lower()), '')\n",
    "                out_set.add('%s\\t%s\\t%s\\t%s\\n' % (name1, name2a, name2b, score))\n",
    "\n",
    "with open('phenotype.mapping.gwascat.tsv', 'w') as f:                    \n",
    "    for out_str in out_set:\n",
    "        f.write(out_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load pre-labeled annotations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded mapping for 623 relations.\n"
     ]
    }
   ],
   "source": [
    "phen_map = dict()\n",
    "phen_scores = dict()\n",
    "with open('util/phenotype.mapping.gwascat.annotated.tsv') as f:                    \n",
    "    for line in f:\n",
    "        fields = line.strip().split('\\t')\n",
    "        fields = [re.sub('\"', '', f) for f in fields]\n",
    "        orig_name, glob_name, loc_name, score = fields\n",
    "\n",
    "        phen_scores[(orig_name.lower(), glob_name.lower(), loc_name.lower())] = score\n",
    "        # change the tuple below to ('3',) in order to look at only maximally \n",
    "        # precise phenotypes\n",
    "        if score in ('2', '3',):\n",
    "            key = (glob_name, loc_name)\n",
    "            if key not in phen_map: phen_map[key] = set()\n",
    "            phen_map[key].add(orig_name) \n",
    "\n",
    "print 'Loaded mapping for %d relations.' % len(phen_map)            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recall relative to GWAS Catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3285 96 642 4023\n",
      "Biggest omissions: [(25742292, 18), (19197348, 17), (24625756, 14), (23400010, 14), (24483146, 13), (21810271, 11), (23770605, 11), (24121790, 10), (22747683, 10), (24058526, 10), (25086665, 8), (21738487, 8), (22216198, 8), (22493691, 7), (24941225, 7)]\n"
     ]
    }
   ],
   "source": [
    "confirmed_assocs_gwcat = list()\n",
    "\n",
    "# display directly the results we found\n",
    "n_correct, n_imprecise, n_missing, n_wrong, n_total, n_new = 0, 0, 0, 0, 0, 0\n",
    "invalid_per_paper = { a.paper.pubmed_id : 0 for a in assocs }\n",
    "seen = set()\n",
    "for a in assocs:\n",
    "    if (a.paper.pubmed_id, a.snp.rs_id, a.phenotype.name) in seen: continue\n",
    "    seen.add((a.paper.pubmed_id, a.snp.rs_id, a.phenotype.name))\n",
    "    \n",
    "    gold_phen_set = {a.phenotype.name} # gwc phenotype string\n",
    "    # load the set of gwasdb phenotypes to which the snp was mapped in this paper\n",
    "    pred_phen_set = rel_dict.get((str(a.paper.pubmed_id), a.snp.rs_id), {}) \n",
    "    # translate these phenotypes into gwc phenotypes using our map\n",
    "    pred_phen_transl_set = {m for p in pred_phen_set for m in phen_map.get(p, {})}\n",
    "\n",
    "    if gold_phen_set & pred_phen_transl_set: \n",
    "        n_correct += 1\n",
    "        n_total += 1\n",
    "        # record the corresponding gwasdb associations as having been correctly recovered\n",
    "        correct_phenotypes = [p for p in pred_phen_set if phen_map.get(p, set()) & gold_phen_set]\n",
    "        for p in correct_phenotypes:\n",
    "            confirmed_assocs_gwcat.append( (str(a.paper.pubmed_id), a.snp.rs_id, p) )\n",
    "        \n",
    "    else:\n",
    "        if paper_contains(a.paper.pubmed_id, a.snp.rs_id):\n",
    "            if a.paper.pubmed_id == 25133637:\n",
    "                print a.snp.rs_id, gold_phen_set, pred_phen_set, pred_phen_transl_set\n",
    "            if pred_phen_set:\n",
    "                n_wrong += 1\n",
    "            else:\n",
    "                n_missing += 1\n",
    "            n_total += 1\n",
    "            invalid_per_paper[a.paper.pubmed_id] += 1\n",
    "\n",
    "print n_correct, n_wrong, n_missing, n_total\n",
    "\n",
    "print 'Biggest omissions:', sorted(invalid_per_paper.items(), key=lambda x: x[1], reverse=True)[:15]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manually evaluating precision"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We measure precision over associations that haven't been confirmed by either GWAS Catalog or GWAS Central."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relations in GWASdb: 6493\n",
      "Relations confirmed via GWAS Central: 2475\n",
      "Relations confirmed via GWAS Catalog: 3290\n",
      "Relations confirmed via at least one database: 3511\n",
      "Unconfirmed assocs: 2982\n"
     ]
    }
   ],
   "source": [
    "assocs_gwdb = set([(pmid, rsid, phen) for pmid, rsid, _, phen in associations])\n",
    "print 'Relations in GWASdb: %d' % len(assocs_gwdb)\n",
    "\n",
    "confirmed_assocs_gwcen, confirmed_assocs_gwcat = set(confirmed_assocs_gwcen), set(confirmed_assocs_gwcat)\n",
    "print 'Relations confirmed via GWAS Central: %d' % len(confirmed_assocs_gwcen)\n",
    "print 'Relations confirmed via GWAS Catalog: %d' % len(confirmed_assocs_gwcat)\n",
    "\n",
    "confirmed_assocs = (assocs_gwdb & set(confirmed_assocs_gwcen)) | (assocs_gwdb & set(confirmed_assocs_gwcat))\n",
    "unconfirmed_assocs = assocs_gwdb - confirmed_assocs\n",
    "\n",
    "print 'Relations confirmed via at least one database: %d' % len(confirmed_assocs)\n",
    "print 'Unconfirmed assocs: %d' % len(unconfirmed_assocs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import random \n",
    "U = list(unconfirmed_assocs)\n",
    "random.shuffle(U)\n",
    "random_subset = list(U[:100])\n",
    "random_subset = sorted(random_subset)\n",
    "with open('rels.discovered.tsv', 'w') as f:\n",
    "    for pmid, rsid, (glob_phen, loc_phen) in random_subset:\n",
    "#         print pmid, rsid, (glob_phen, loc_phen)\n",
    "        f.write('%s\\t%s\\t%s\\t%s\\n' % (pmid, rsid, glob_phen, loc_phen) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at statistics of GWAS Catalog and GWAS Central"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Searching over 589 documents\n",
      "Of these, 430 are in GWAS Central\n",
      "\n",
      "GWAS Central has 6086 associations\n",
      "GWAS Catalog has 9747 associations\n",
      "GWASdb has 7362 associations\n",
      "\n",
      "GWAS Central has 5914 significant variant tuples\n",
      "GWAS Catalog has 8384 significant variant tuples\n",
      "GWASdb has 6302 significant variant tuples\n",
      "\n",
      "GWAS Central has 364 unique significant variant tuples\n",
      "GWAS Catalog has 2026 unique significant variant tuples\n",
      "GWASdb has 2848 unique significant variant tuples\n"
     ]
    }
   ],
   "source": [
    "from db.kb import KnowledgeBase\n",
    "\n",
    "# load all the associations in each database\n",
    "kb = KnowledgeBase()\n",
    "gwcen_a = set([(str(a.paper.pubmed_id), a.snp.rs_id, a.phenotype.name) for pmid in pmids for a in kb.assoc_by_pmid(pmid) if a.source == 'gwas_central' and a.pvalue < 1e-5])\n",
    "gwcat_a = [(str(a.paper.pubmed_id), a.snp.rs_id, a.phenotype.name) for pmid in pmids for a in kb.assoc_by_pmid(pmid) if a.source == 'gwas_catalog' and a.pvalue < 1e-5]\n",
    "\n",
    "# how many of these documents were actually in GWAS Central?\n",
    "gwcen_papers = set([a[0] for a in gwcen_a])\n",
    "\n",
    "print 'Searching over %d documents' % len(pmids)\n",
    "print 'Of these, %d are in GWAS Central' % len(gwcen_papers)\n",
    "print\n",
    "print 'GWAS Central has %d associations' % len(gwcen_a)\n",
    "print 'GWAS Catalog has %d associations' % len(gwcat_a)\n",
    "print 'GWASdb has %d associations' % len(associations)\n",
    "print\n",
    "\n",
    "# we can't compare them directly, because phenotypes don't match; insteal we look at (pmid, rsid) tuples\n",
    "gwcen_t = set([ (a[0], a[1]) for a in gwcen_a ])\n",
    "gwcat_t = set([ (a[0], a[1]) for a in gwcat_a ])\n",
    "gwdb_t = set([ (pmid, rsid) for pmid, rsid, _, _ in associations ])\n",
    "\n",
    "print 'GWAS Central has %d significant variant tuples' % len(gwcen_t)\n",
    "print 'GWAS Catalog has %d significant variant tuples' % len(gwcat_t)\n",
    "print 'GWASdb has %d significant variant tuples' % len(gwdb_t)\n",
    "print\n",
    "\n",
    "# how many of these are unique to each database\n",
    "all_t = gwcen_t | gwcat_t | gwdb_t\n",
    "gwcen_t_uq = gwcen_t - gwcat_t - gwdb_t\n",
    "gwcat_t_uq = gwcat_t - gwcen_t - gwdb_t\n",
    "gwdb_t_uq = gwdb_t - gwcen_t - gwcat_t\n",
    "\n",
    "print 'GWAS Central has %d unique significant variant tuples' % len(gwcen_t_uq)\n",
    "print 'GWAS Catalog has %d unique significant variant tuples' % len(gwcat_t_uq)\n",
    "print 'GWASdb has %d unique significant variant tuples' % len(gwdb_t_uq)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
